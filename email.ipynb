{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00e8752",
   "metadata": {},
   "source": [
    "# Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38345f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09334a9a",
   "metadata": {},
   "source": [
    "# Data Collection and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e1e62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data from csv file to a pandas DataFrame\n",
    "dataset=pd.read_csv('email_data.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02b544",
   "metadata": {},
   "source": [
    "# Replacing null values with a null string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511e1d1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataset.where((pd.notnull(dataset)),'')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9cbaa6",
   "metadata": {},
   "source": [
    "# checking number of rows and columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86516d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361997b",
   "metadata": {},
   "source": [
    "# Label Encoding.... Label spam mail as 0 and ham mail as 1 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3abf62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset['Category']=='spam','Category']=0\n",
    "dataset.loc[dataset['Category']=='ham','Category']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb026af2",
   "metadata": {},
   "source": [
    "# separating the data as texts and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921d5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset['Message']\n",
    "y=dataset['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7229cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: Message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07835683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5567    0\n",
       "5568    1\n",
       "5569    1\n",
       "5570    1\n",
       "5571    1\n",
       "Name: Category, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46517237",
   "metadata": {},
   "source": [
    "# splitting the data into training data and testing data.... We will train 80% of data and rest 20% data will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "443e7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f13a4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114    No I'm good for the movie, is it ok if I leave...\n",
       "3589    If you were/are free i can give. Otherwise nal...\n",
       "3095    Have you emigrated or something? Ok maybe 5.30...\n",
       "1012          I just got home babe, are you still awake ?\n",
       "3320                      Kay... Since we are out already\n",
       "                              ...                        \n",
       "4931    Hi, the SEXYCHAT girls are waiting for you to ...\n",
       "3264                              So u gonna get deus ex?\n",
       "1653    For ur chance to win a £250 cash every wk TXT:...\n",
       "2607    R U &SAM P IN EACHOTHER. IF WE MEET WE CAN GO ...\n",
       "2732    Mm feeling sleepy. today itself i shall get th...\n",
       "Name: Message, Length: 4457, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f3754",
   "metadata": {},
   "source": [
    "# printing shape of x, x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b46794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0274ca06",
   "metadata": {},
   "source": [
    "# Feature Extraction..... converting the text data into numarical data that can be used as input to Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87c1a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using TfidfVectorizer .... it will give scores to words depending on how many times a particular word is repeated in the mail\n",
    "# min_df... wwill considerr only those wwords which are repeated at least twice.\n",
    "# stop_words.... these are the words that are to be ignored.\n",
    "# comverting to lowercase will be good for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0a4a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction = TfidfVectorizer(min_df=1, stop_words='english', lowercase=True)\n",
    "x_train_feature = feature_extraction.fit_transform(x_train)\n",
    "x_test_feature = feature_extraction.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f8fe4",
   "metadata": {},
   "source": [
    "# converting y_train and y_test values as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f6c10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype('int')\n",
    "y_test=y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a558c938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114    No I'm good for the movie, is it ok if I leave...\n",
       "3589    If you were/are free i can give. Otherwise nal...\n",
       "3095    Have you emigrated or something? Ok maybe 5.30...\n",
       "1012          I just got home babe, are you still awake ?\n",
       "3320                      Kay... Since we are out already\n",
       "                              ...                        \n",
       "4931    Hi, the SEXYCHAT girls are waiting for you to ...\n",
       "3264                              So u gonna get deus ex?\n",
       "1653    For ur chance to win a £250 cash every wk TXT:...\n",
       "2607    R U &SAM P IN EACHOTHER. IF WE MEET WE CAN GO ...\n",
       "2732    Mm feeling sleepy. today itself i shall get th...\n",
       "Name: Message, Length: 4457, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdb49dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3422)\t0.6418008618863358\n",
      "  (0, 3960)\t0.40459749284424307\n",
      "  (0, 4776)\t0.2937599690543961\n",
      "  (0, 4486)\t0.4933198981059812\n",
      "  (0, 3101)\t0.30778739607068667\n",
      "  (1, 3855)\t0.4410710256765374\n",
      "  (1, 4574)\t0.4410710256765374\n",
      "  (1, 2534)\t0.4410710256765374\n",
      "  (1, 814)\t0.4410710256765374\n",
      "  (1, 4555)\t0.4205367990464199\n",
      "  (1, 2902)\t0.2120712188920981\n",
      "  (2, 3398)\t0.5133141633463273\n",
      "  (2, 1317)\t0.34462014146959175\n",
      "  (2, 432)\t0.4077104256374456\n",
      "  (2, 4294)\t0.36445133334144264\n",
      "  (2, 2503)\t0.5133141633463273\n",
      "  (2, 4776)\t0.2349500626979615\n",
      "  (3, 1138)\t0.6489221209014988\n",
      "  (3, 1160)\t0.44843330753299465\n",
      "  (3, 3378)\t0.38536596088088965\n",
      "  (3, 3118)\t0.3618113574629584\n",
      "  (3, 3778)\t0.31367701143832527\n",
      "  (4, 3805)\t1.0\n",
      "  (5, 3731)\t0.6020708068994186\n",
      "  (5, 7381)\t0.7984426989330436\n",
      "  :\t:\n",
      "  (4454, 348)\t0.2816333253882664\n",
      "  (4454, 110)\t0.3000941484572203\n",
      "  (4454, 2067)\t0.25658354936739225\n",
      "  (4454, 4488)\t0.3000941484572203\n",
      "  (4454, 651)\t0.3000941484572203\n",
      "  (4454, 373)\t0.23959800001827322\n",
      "  (4454, 796)\t0.2816333253882664\n",
      "  (4454, 7430)\t0.1801037942222884\n",
      "  (4454, 7343)\t0.4498896407891956\n",
      "  (4454, 6911)\t0.1653057679612594\n",
      "  (4454, 6902)\t0.21937394005137992\n",
      "  (4454, 1621)\t0.18784292855815676\n",
      "  (4454, 7311)\t0.1949753381818719\n",
      "  (4454, 1665)\t0.21130971337962476\n",
      "  (4454, 7011)\t0.14040083857773877\n",
      "  (4455, 2434)\t0.617585164773377\n",
      "  (4455, 5750)\t0.5526101356478642\n",
      "  (4455, 4311)\t0.3634744995680554\n",
      "  (4455, 3424)\t0.4255548030452034\n",
      "  (4456, 6077)\t0.5490155787253892\n",
      "  (4456, 4416)\t0.4542018586423069\n",
      "  (4456, 2724)\t0.40079007123433724\n",
      "  (4456, 5910)\t0.3950554110813791\n",
      "  (4456, 6769)\t0.2873431830527075\n",
      "  (4456, 2135)\t0.30498360947948605\n"
     ]
    }
   ],
   "source": [
    "print(x_train_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3e5ff",
   "metadata": {},
   "source": [
    "# training the model.... logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26a119c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88b200a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the logistic regression model with the training data.\n",
    "model.fit(x_train_feature,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e237b",
   "metadata": {},
   "source": [
    "# Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03e263be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on training data\n",
    "prediction_on_training_data = model.predict(x_train_feature)\n",
    "accuracy_on_training_data=accuracy_score(y_train, prediction_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6892573a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is :  0.9679156383217411\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training data is : \",accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc0a2b",
   "metadata": {},
   "source": [
    "# prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c77cebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_testing_data = model.predict(x_test_feature)\n",
    "accuracy_on_testing_data=accuracy_score(y_test, prediction_on_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "216684d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data is :  0.9668161434977578\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on testing data is : \",accuracy_on_testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7947cf",
   "metadata": {},
   "source": [
    "# Building a predictive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce75fe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "This is a spam mail\n"
     ]
    }
   ],
   "source": [
    "mail=[\"FREE FREE FREE ! By clicking on the folloiwng link you will get FREE laptop and FREE samsung Tablet. Now do not wait and just click on link and get your GIFT for FREE\"]\n",
    "\n",
    "# convert text to feature vector\n",
    "mail_feature=feature_extraction.transform(mail)\n",
    "\n",
    "# making prediction\n",
    "prediction = model.predict(mail_feature)\n",
    "# print(prediction)\n",
    "if prediction[0]==0:\n",
    "    print(\"This is a spam mail\")\n",
    "else:\n",
    "    print(\"This is a ham mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97c16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
